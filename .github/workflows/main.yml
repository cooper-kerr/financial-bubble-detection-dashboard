name: Daily CSV Update

on:
  schedule:
    # Runs every day at 21:30 UTC = 4:30 PM EST
    - cron: '30 21 * * *'
  workflow_dispatch:  # allows manual triggering

jobs:
  update-csv:
    runs-on: ubuntu-latest

    permissions:
      contents: write  # allow git push

    steps:
      # Step 1: Checkout repository (with full history for safe commit)
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      # Step 2: Set up Python
      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      # Step 3: Install dependencies
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas numpy yfinance scipy fredapi

      # Step 4: Run the scraper
      - name: Run YF Data Scraper
        run: python scripts/YF-Data-Scraper.py
        env:
          FRED_API_KEY: ${{ secrets.FRED_API_KEY }}

      # Step 5: Verify output directory
      - name: Verify CSV output
        run: |
          echo "Checking data/csv directory..."
          ls -l data/csv || echo "‚ö†Ô∏è No CSV directory found!"

      # Step 6: Commit and push updated CSVs
      - name: Commit and push CSV updates
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          git add data/csv
          
          # Check if there are actual changes before committing
          if git diff --cached --quiet; then
            echo "‚úÖ No changes detected ‚Äî skipping commit."
          else
            git commit -m "Automated CSV update: $(date -u '+%Y-%m-%d %H:%M:%S UTC')"
            git push origin HEAD:${{ github.ref_name }}
            echo "üöÄ CSV updates committed and pushed."
          fi
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
